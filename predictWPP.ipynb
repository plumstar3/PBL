{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5578556",
   "metadata": {},
   "source": [
    "## 1: ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ddc366b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupShuffleSplit, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, log_loss, brier_score_loss, classification_report\n",
    "import numpy as np\n",
    "from typing import Optional\n",
    "import os\n",
    "# 出力幅を広げる設定\n",
    "pd.set_option('display.width', 1000)  # 任意の幅に設定（例: 200）\n",
    "pd.set_option('display.max_columns', None)  # 全ての列を表示\n",
    "#pd.set_option('display.expand_frame_repr', False)  # 横に広げて表示（改行しない）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaae261f",
   "metadata": {},
   "source": [
    "## 2: データ読み込み・前処理関数の定義 (load_and_process_pbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9953bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_pbp(db_path: str, limit_rows: Optional[int] = None) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    SQLiteデータベースからプレイバイプレイデータを読み込み、データ型を処理し、\n",
    "    ホームチームの勝敗情報を計算して元のデータに結合します。\n",
    "    (省略... 関数の内容は元のスクリプトと同じ)\n",
    "    \"\"\"\n",
    "    print(f\"--- Starting data loading and processing ---\")\n",
    "    print(f\"Database path: {db_path}\")\n",
    "    if limit_rows:\n",
    "        print(f\"Row limit: {limit_rows}\")\n",
    "    else:\n",
    "        print(\"Row limit: None (loading all rows)\")\n",
    "\n",
    "    try:\n",
    "        # 1. SQLiteデータベースへの接続\n",
    "        print(\"Connecting to database...\")\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        print(\"Database connection successful.\")\n",
    "\n",
    "        # 2. SQLクエリの構築\n",
    "        query = \"\"\"\n",
    "        SELECT\n",
    "            game_id, eventnum, eventmsgtype, eventmsgactiontype, \n",
    "            period, pctimestring,\n",
    "            homedescription, neutraldescription, visitordescription,\n",
    "            score, scoremargin\n",
    "        FROM\n",
    "            play_by_play\n",
    "        \"\"\"\n",
    "        if limit_rows:\n",
    "            query += f\" LIMIT {limit_rows};\"\n",
    "        else:\n",
    "            query += \";\"\n",
    "\n",
    "        print(\"Executing SQL query...\")\n",
    "        # 3. クエリ実行とDataFrameへの読み込み\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "        print(f\"Successfully loaded {len(df)} rows into DataFrame.\")\n",
    "\n",
    "        # 4. データベース接続を閉じる\n",
    "        conn.close()\n",
    "        print(\"Database connection closed.\")\n",
    "\n",
    "        # 5. データ型の確認と変換\n",
    "        print(\"Processing data types...\")\n",
    "        df['game_id'] = df['game_id'].astype(str)\n",
    "        df['pctimestring'] = df['pctimestring'].astype(str)\n",
    "        df['score'] = df['score'].astype(str)\n",
    "        df['scoremargin'] = df['scoremargin'].astype(str)\n",
    "        df['eventnum'] = pd.to_numeric(df['eventnum'], errors='coerce')\n",
    "        df['eventmsgtype'] = pd.to_numeric(df['eventmsgtype'], errors='coerce')\n",
    "        df['eventmsgactiontype'] = pd.to_numeric(df['eventmsgactiontype'], errors='coerce') \n",
    "        df['period'] = pd.to_numeric(df['period'], errors='coerce')\n",
    "        desc_cols = ['homedescription', 'neutraldescription', 'visitordescription']\n",
    "        for col in desc_cols:\n",
    "            df[col] = df[col].fillna('')\n",
    "        print(\"Data type processing complete.\")\n",
    "\n",
    "        # --- 最終スコアの取得と勝敗判定 ---\n",
    "        print(\"\\nAttempting to determine game outcomes...\")\n",
    "        game_outcomes = pd.Series(dtype=int) # 空のSeriesを初期化\n",
    "\n",
    "        end_game_events = df[(df['eventmsgtype'] == 13) & (df['score'].str.contains(' - ', na=False))].copy()\n",
    "\n",
    "        if not end_game_events.empty:\n",
    "            end_game_events = end_game_events.dropna(subset=['period'])\n",
    "            if not end_game_events.empty:\n",
    "                end_game_events['period'] = end_game_events['period'].astype(int)\n",
    "                final_events = end_game_events.sort_values('period').groupby('game_id').last()\n",
    "\n",
    "                if 'score' in final_events.columns:\n",
    "                    scores_split = final_events['score'].str.split(' - ', expand=True)\n",
    "                    scores_split.columns = ['home_score', 'visitor_score']\n",
    "                    scores_split['home_score'] = pd.to_numeric(scores_split['home_score'], errors='coerce')\n",
    "                    scores_split['visitor_score'] = pd.to_numeric(scores_split['visitor_score'], errors='coerce')\n",
    "                    scores_split = scores_split.dropna(subset=['home_score', 'visitor_score'])\n",
    "\n",
    "                    if not scores_split.empty:\n",
    "                        scores_split['home_win'] = (scores_split['home_score'] > scores_split['visitor_score']).astype(int)\n",
    "                        game_outcomes = scores_split['home_win']\n",
    "                        print(f\"Determined outcomes for {len(game_outcomes)} games.\")\n",
    "                        if limit_rows:\n",
    "                            print(\"[Warning] Game outcomes may be incomplete due to the row limit.\")\n",
    "                    # else: (No need for print here in a function, caller can check)\n",
    "                # else:\n",
    "            # else:\n",
    "        # else:\n",
    "\n",
    "        print(\"Merging game outcomes back to the main DataFrame...\")\n",
    "        if not game_outcomes.empty:\n",
    "             df_with_outcome = df.merge(game_outcomes.rename('home_win'), on='game_id', how='left')\n",
    "        else:\n",
    "             print(\"No game outcomes determined, adding 'home_win' column with NaN.\")\n",
    "             df['home_win'] = pd.NA\n",
    "             df_with_outcome = df\n",
    "\n",
    "        print(\"--- Data loading and processing finished ---\")\n",
    "        return df_with_outcome\n",
    "\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"\\n--- Database Error ---\")\n",
    "        print(f\"An error occurred while interacting with the database: {e}\")\n",
    "        return None\n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\n--- File Not Found Error ---\")\n",
    "        print(f\"Error: The database file was not found at the specified path: {db_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"\\n--- An Unexpected Error Occurred ---\")\n",
    "        print(f\"Error details: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758cad44",
   "metadata": {},
   "source": [
    "## 3: 特徴量エンジニアリング用関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b81bae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_time_to_seconds(time_str):\n",
    "    \"\"\" 'MM:SS' 形式の文字列を秒に変換 \"\"\"\n",
    "    if isinstance(time_str, str) and ':' in time_str:\n",
    "        try:\n",
    "            minutes, seconds = map(int, time_str.split(':'))\n",
    "            return minutes * 60 + seconds\n",
    "        except ValueError:\n",
    "            return None # パースエラー\n",
    "    return None\n",
    "\n",
    "def calculate_seconds_elapsed(row):\n",
    "    \"\"\" 試合開始からの経過秒数を計算 \"\"\"\n",
    "    period = row['period']\n",
    "    pctimestring = row['pctimestring']\n",
    "\n",
    "    if pd.isna(period) or period < 1:\n",
    "        return None\n",
    "\n",
    "    seconds_in_period = parse_time_to_seconds(pctimestring)\n",
    "    if seconds_in_period is None:\n",
    "        return None\n",
    "\n",
    "    seconds_per_period = 720 if period <= 4 else 300\n",
    "    seconds_elapsed_in_current_period = seconds_per_period - seconds_in_period\n",
    "\n",
    "    if seconds_elapsed_in_current_period < 0 or seconds_elapsed_in_current_period > seconds_per_period:\n",
    "         return None\n",
    "\n",
    "    if period <= 4:\n",
    "        total_seconds_elapsed = (period - 1) * 720 + seconds_elapsed_in_current_period\n",
    "    else:\n",
    "        total_seconds_elapsed = 4 * 720 + (period - 5) * 300 + seconds_elapsed_in_current_period\n",
    "    return total_seconds_elapsed\n",
    "\n",
    "def process_score_margin(margin_str):\n",
    "    \"\"\" scoremargin を数値に変換 ('TIE' -> 0) \"\"\"\n",
    "    if margin_str == 'TIE':\n",
    "        return 0\n",
    "    elif pd.isna(margin_str) or margin_str == '':\n",
    "         return None\n",
    "    else:\n",
    "        try:\n",
    "            return int(str(margin_str).replace('+', ''))\n",
    "        except ValueError:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62ada2e",
   "metadata": {},
   "source": [
    "## 4 設定とデータ読み込みの実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d926ad6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting data loading and processing ---\n",
      "Database path: C:\\Users\\amilu\\Projects\\vsCodeFile\\PBL\\nba.sqlite\n",
      "Row limit: 45616\n",
      "Connecting to database...\n",
      "Database connection successful.\n",
      "Executing SQL query...\n",
      "Successfully loaded 45616 rows into DataFrame.\n",
      "Database connection closed.\n",
      "Processing data types...\n",
      "Data type processing complete.\n",
      "\n",
      "Attempting to determine game outcomes...\n",
      "Determined outcomes for 99 games.\n",
      "[Warning] Game outcomes may be incomplete due to the row limit.\n",
      "Merging game outcomes back to the main DataFrame...\n",
      "--- Data loading and processing finished ---\n",
      "\n",
      "Shape of loaded data: (45616, 12)\n"
     ]
    }
   ],
   "source": [
    "#研究室PC用path\n",
    "db_file = r'C:\\Users\\amilu\\Projects\\vsCodeFile\\PBL\\nba.sqlite'\n",
    "#ノートPC用path\n",
    "#db_file = 'C:\\Workspace\\PBL\\\\nba.sqlite'\n",
    "\n",
    "limit_rows = 45616\n",
    "# limit_rows = None # 全データの場合\n",
    "\n",
    "df_processed = load_and_process_pbp(db_file, limit_rows=limit_rows)\n",
    "\n",
    "# 読み込み結果の確認\n",
    "if df_processed is not None:\n",
    "    print(\"\\nShape of loaded data:\", df_processed.shape)\n",
    "    df_processed.head() # 先頭数行を表示\n",
    "else:\n",
    "    print(\"Data loading failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dc97f4",
   "metadata": {},
   "source": [
    "## 5: 特徴量エンジニアリングの実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19bce3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Feature Engineering ---\n",
      "Calculating total seconds elapsed...\n",
      "Processing score margin...\n",
      "Forward filling missing 'numeric_score_margin' within each game...\n",
      "Generating composite event ID...\n",
      "Composite event ID generation complete.\n",
      "\n",
      "Preview of processed time, score margin, and composite event ID features:\n",
      "         game_id  eventnum  eventmsgtype  eventmsgactiontype  composite_event_id  seconds_elapsed  numeric_score_margin\n",
      "2225  0029600001         1            12                   0               12000                0                   NaN\n",
      "2226  0029600001         2            10                   0               10000                0                   NaN\n",
      "2227  0029600001         4             1                   5                1005               21                  -2.0\n",
      "2228  0029600001         5             6                   2                6002               21                  -2.0\n",
      "2229  0029600001         6             3                  10                3010               21                  -3.0\n",
      "2230  0029600001         7             1                   1                1001               54                  -1.0\n",
      "2233  0029600001         8             1                   6                1006               58                   1.0\n",
      "2234  0029600001         9             1                   5                1005               74                  -1.0\n",
      "2235  0029600001        10             5                   1                5001               86                  -1.0\n",
      "2236  0029600001        11             1                   7                1007               91                  -3.0\n",
      "2237  0029600001        12             5                   4                5004              105                  -3.0\n",
      "2238  0029600001        13             1                   3                1003              121                  -5.0\n",
      "2239  0029600001        14             2                   5                2005              134                  -5.0\n",
      "2240  0029600001        15             4                   0                4000              135                  -5.0\n",
      "2241  0029600001        16             5                   4                5004              157                  -5.0\n"
     ]
    }
   ],
   "source": [
    "if df_processed is not None:\n",
    "    print(\"\\n--- Feature Engineering ---\")\n",
    "\n",
    "    print(\"Calculating total seconds elapsed...\")\n",
    "    df_processed['seconds_elapsed'] = df_processed.apply(calculate_seconds_elapsed, axis=1)\n",
    "\n",
    "    print(\"Processing score margin...\")\n",
    "    # Step 1: 'TIE' や数値変換可能なものを数値に変換 (NoneはNoneのまま)\n",
    "    df_processed['numeric_score_margin'] = df_processed['scoremargin'].apply(process_score_margin)\n",
    "\n",
    "    # Step 2: game_id ごとに並べ替え、欠損値 (None) を直前の有効な値で前方補完 (ffill)\n",
    "    print(\"Forward filling missing 'numeric_score_margin' within each game...\")\n",
    "    # game_id と eventnum でソートすることが重要\n",
    "    df_processed = df_processed.sort_values(by=['game_id', 'eventnum'])\n",
    "    df_processed['numeric_score_margin'] = df_processed.groupby('game_id')['numeric_score_margin'].ffill()\n",
    "\n",
    "    # ffill 後も NaN が残る場合がある（ゲームの最初の数プレイなど、前に有効な値がない場合）\n",
    "    # これらは後続の dropna で処理されるか、別途 0 などで埋める判断も可能\n",
    "    # print(\"NaN count in numeric_score_margin after ffill:\", df_processed['numeric_score_margin'].isnull().sum())\n",
    "    # 2.3 Generate Composite Event ID\n",
    "    print(\"Generating composite event ID...\")\n",
    "    # eventmsgtype と eventmsgactiontype が数値であることを確認 (NaNの場合は計算結果もNaNになる)\n",
    "    # 複合IDの計算前に、これらのカラムの欠損値処理が必要か検討\n",
    "    # 例: df_processed['eventmsgtype'].fillna(0, inplace=True) # 欠損を0で埋める場合\n",
    "    #     df_processed['eventmsgactiontype'].fillna(0, inplace=True)\n",
    "    \n",
    "    # もし欠損値のまま計算すると、結果がNaNになるため、後続のdropnaで除外されるか、\n",
    "    # またはfillna(例えば -1 や特定の予約ID) で埋める\n",
    "    df_processed['composite_event_id'] = (df_processed['eventmsgtype'] * 1000 + df_processed['eventmsgactiontype'])\n",
    "    # 欠損値から生じたNaNを、例えば不明なID (-1など) で埋める場合\n",
    "    # df_processed['composite_event_id'] = df_processed['composite_event_id'].fillna(-1).astype(int)\n",
    "    print(\"Composite event ID generation complete.\")\n",
    "\n",
    "\n",
    "    # 結果の確認\n",
    "    print(\"\\nPreview of processed time, score margin, and composite event ID features:\")\n",
    "    print(df_processed[['game_id', 'eventnum', 'eventmsgtype', 'eventmsgactiontype', 'composite_event_id', 'seconds_elapsed', 'numeric_score_margin']].head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7572d0cb",
   "metadata": {},
   "source": [
    "## 6: モデル用データ準備 (フィルタリング)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1bbda1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data Preparation for Modeling ---\n",
      "Filtering data for modeling...\n",
      "Rows before filtering: 45616\n",
      "Rows after filtering invalid/unnecessary entries: 44791\n"
     ]
    }
   ],
   "source": [
    "if df_processed is not None:\n",
    "    print(\"\\n--- Data Preparation for Modeling ---\")\n",
    "    print(\"Filtering data for modeling...\")\n",
    "    initial_rows = len(df_processed)\n",
    "    \n",
    "    # 欠損値の確認 (フィルタリング前)\n",
    "    # print(\"NaN counts before filtering:\")\n",
    "    # print(df_processed[['home_win', 'seconds_elapsed', 'numeric_score_margin', 'period']].isnull().sum())\n",
    "\n",
    "    model_df = df_processed.dropna(subset=['home_win', 'seconds_elapsed', 'numeric_score_margin', 'period', 'composite_event_id'])\n",
    "    model_df = model_df[model_df['period'] > 0]\n",
    "    model_df = model_df[model_df['eventmsgtype'] != 12] # \"Start Period\" イベントを除外\n",
    "\n",
    "    filtered_rows = len(model_df)\n",
    "    print(f\"Rows before filtering: {initial_rows}\")\n",
    "    print(f\"Rows after filtering invalid/unnecessary entries: {filtered_rows}\")\n",
    "    \n",
    "    if filtered_rows > 0:\n",
    "        model_df.head()\n",
    "    else:\n",
    "        print(\"No data left after filtering.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d858e58",
   "metadata": {},
   "source": [
    "## 7: 特徴量とターゲットの選択、訓練/テスト分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5cacb381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying One-Hot Encoding to 'composite_event_id'...\n",
      "Shape after One-Hot Encoding: (44791, 92)\n",
      "New columns created by One-Hot Encoding (first few):\n",
      "['event_1001', 'event_1002', 'event_1003', 'event_1004', 'event_1005']\n",
      "\n",
      "Total features for the model: 80\n",
      "\n",
      "Splitting data into training and testing sets (game-aware)...\n",
      "Training set size: 35629\n",
      "Testing set size: 9162\n"
     ]
    }
   ],
   "source": [
    "if 'model_df' in locals() and not model_df.empty:\n",
    "    # --- One-Hot Encoding for composite_event_id ---\n",
    "    print(\"Applying One-Hot Encoding to 'composite_event_id'...\")\n",
    "    # NaNや不明なIDで埋めた場合は、それも1つのカテゴリとして扱われる\n",
    "    # あまりに多くのカテゴリがある場合は注意が必要 (次元の呪い)\n",
    "    # ここでは、dropnaでcomposite_event_idがNaNの行は除外されている前提\n",
    "    \n",
    "    # One-Hotエンコーディングを実行し、元のDataFrameに結合\n",
    "    # get_dummiesはNaNを無視するか、専用のカテゴリを作るか選択できる\n",
    "    # dtype=int で 0/1 の整数型にする\n",
    "    model_df_encoded = pd.get_dummies(model_df, columns=['composite_event_id'], prefix='event', dtype=int)\n",
    "    print(f\"Shape after One-Hot Encoding: {model_df_encoded.shape}\")\n",
    "    print(\"New columns created by One-Hot Encoding (first few):\")\n",
    "    print([col for col in model_df_encoded.columns if col.startswith('event_')][:5])\n",
    "\n",
    "\n",
    "    # --- 特徴量とターゲットの選択 ---\n",
    "    # 元の特徴量に、One-Hotエンコードされた列を追加\n",
    "    base_features = ['numeric_score_margin', 'seconds_elapsed']\n",
    "    one_hot_event_features = [col for col in model_df_encoded.columns if col.startswith('event_')]\n",
    "    \n",
    "    features = base_features + one_hot_event_features\n",
    "    target = 'home_win'\n",
    "\n",
    "    print(f\"\\nTotal features for the model: {len(features)}\")\n",
    "    # print(\"Selected features:\", features) # 長くなるのでコメントアウト\n",
    "\n",
    "    X = model_df_encoded[features]\n",
    "    y = model_df_encoded[target].astype(int) # model_df_encoded を使用\n",
    "\n",
    "    print(\"\\nSplitting data into training and testing sets (game-aware)...\")\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    \n",
    "    if model_df_encoded['game_id'].nunique() < 2: # model_df_encoded を使用\n",
    "        print(\"Warning: Not enough unique games for GroupShuffleSplit...\")\n",
    "        # (代替処理は省略、元のコードと同様)\n",
    "        if len(X) > 1:\n",
    "             train_idx, test_idx = train_test_split(range(len(X)), test_size=0.2, random_state=42, stratify=y if y.nunique() > 1 else None)\n",
    "        else:\n",
    "            train_idx, test_idx = range(len(X)), []\n",
    "            print(\"Too few samples for splitting. Using all as training data.\")\n",
    "    else:\n",
    "        train_idx, test_idx = next(gss.split(X, y, groups=model_df_encoded['game_id'])) # model_df_encoded を使用\n",
    "\n",
    "    if len(train_idx) > 0 and len(test_idx) > 0:\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        print(f\"Training set size: {len(X_train)}\")\n",
    "        print(f\"Testing set size: {len(X_test)}\")\n",
    "        \n",
    "        # one-hotエンコード後のX_trainの最初の数行を表示して確認\n",
    "        # print(\"\\nSample of X_train after one-hot encoding (first 5 rows, first 10 columns):\")\n",
    "        # print(X_train.iloc[:5, :10])\n",
    "\n",
    "    elif len(train_idx) > 0:\n",
    "        print(f\"Only training data available. Training set size: {len(X_train)}\")\n",
    "        X_test, y_test = pd.DataFrame(columns=X.columns), pd.Series(dtype=y.dtype)\n",
    "    else:\n",
    "        print(\"Could not create valid train/test splits.\")\n",
    "else:\n",
    "    print(\"Skipping feature selection and train/test split as model_df is not available or empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af041df",
   "metadata": {},
   "source": [
    "## 8: モデル訓練 (スケーリングとロジスティック回帰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e0c91c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Training ---\n",
      "Scaling features...\n",
      "Training Logistic Regression model...\n",
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "if 'X_train' in locals() and not X_train.empty:\n",
    "    print(\"\\n--- Model Training ---\")\n",
    "    print(\"Scaling features...\")\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    \n",
    "    # テストデータがある場合のみスケーリング\n",
    "    if not X_test.empty:\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "    else:\n",
    "        X_test_scaled = np.array([]) # 空の配列\n",
    "\n",
    "    print(\"Training Logistic Regression model...\")\n",
    "    model = LogisticRegression(random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    print(\"Model training complete.\")\n",
    "else:\n",
    "    print(\"Skipping model training as training data is not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a0b565",
   "metadata": {},
   "source": [
    "##  9: 予測と評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e317e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Prediction and Evaluation ---\n",
      "Model Evaluation Results:\n",
      "  Accuracy: 0.6644\n",
      "  ROC AUC:  0.7200\n",
      "  Log Loss: 0.5917\n",
      "  Brier Score: 0.2081\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.70      0.71      5304\n",
      "           1       0.60      0.62      0.61      3858\n",
      "\n",
      "    accuracy                           0.66      9162\n",
      "   macro avg       0.66      0.66      0.66      9162\n",
      "weighted avg       0.67      0.66      0.66      9162\n",
      "\n",
      "\n",
      "Reversing the sign of 'numeric_score_margin' in model_df_test...\n",
      "Sign reversal of 'numeric_score_margin_invation' complete.\n",
      "     scoremargin  numeric_score_margin  numeric_score_margin_invation\n",
      "2227          -2                  -2.0                            2.0\n",
      "2228        None                  -2.0                            2.0\n",
      "2229          -3                  -3.0                            3.0\n",
      "2230          -1                  -1.0                            1.0\n",
      "2233           1                   1.0                           -1.0\n",
      "\n",
      "First 5 rows of test data with predicted win probability:\n",
      "         game_id  eventnum  period pctimestring  score scoremargin  numeric_score_margin  seconds_elapsed  home_win  win_probability_pred  numeric_score_margin_invation\n",
      "2227  0029600001         4       1        11:39  2 - 0          -2                  -2.0               21         1              0.540324                            2.0\n",
      "2228  0029600001         5       1        11:39   None        None                  -2.0               21         1              0.572804                            2.0\n",
      "2229  0029600001         6       1        11:39  3 - 0          -3                  -3.0               21         1              0.642569                            3.0\n",
      "2230  0029600001         7       1        11:06  3 - 2          -1                  -1.0               54         1              0.538894                            1.0\n",
      "2233  0029600001         8       1        11:02  3 - 4           1                   1.0               58         1              0.464927                           -1.0\n"
     ]
    }
   ],
   "source": [
    "if 'model' in locals() and 'X_test_scaled' in locals() and X_test_scaled.shape[0] > 0: # テストデータがあるか確認\n",
    "    print(\"\\n--- Prediction and Evaluation ---\")\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    y_pred_class = model.predict(X_test_scaled)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred_class)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    logloss = log_loss(y_test, y_pred_proba)\n",
    "    brier = brier_score_loss(y_test, y_pred_proba)\n",
    "\n",
    "    print(f\"Model Evaluation Results:\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  ROC AUC:  {auc:.4f}\")\n",
    "    print(f\"  Log Loss: {logloss:.4f}\")\n",
    "    print(f\"  Brier Score: {brier:.4f}\")\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred_class))\n",
    "\n",
    "    # テストデータに予測結果を結合\n",
    "    # model_df_encoded から test_idx を使ってスライスする\n",
    "    model_df_test = model_df_encoded.iloc[test_idx].copy()\n",
    "    model_df_test['win_probability_pred'] = y_pred_proba\n",
    "\n",
    "    # numeric_score_margin の正負反転\n",
    "    if 'numeric_score_margin' in model_df_test.columns:\n",
    "        print(\"\\nReversing the sign of 'numeric_score_margin' in model_df_test...\")\n",
    "        model_df_test['numeric_score_margin_invation'] = model_df_test['numeric_score_margin'] * -1\n",
    "        print(\"Sign reversal of 'numeric_score_margin_invation' complete.\")\n",
    "        print(model_df_test[['scoremargin', 'numeric_score_margin', 'numeric_score_margin_invation']].head())\n",
    "    else:\n",
    "        print(\"\\nWarning: 'numeric_score_margin' column not found in model_df_test.\")\n",
    "\n",
    "\n",
    "    print(\"\\nFirst 5 rows of test data with predicted win probability:\")\n",
    "    # 表示するカラムを調整\n",
    "    display_cols = ['game_id', 'eventnum', 'period', 'pctimestring', 'score', 'scoremargin', 'numeric_score_margin', 'seconds_elapsed', 'home_win', 'win_probability_pred']\n",
    "    if 'numeric_score_margin_invation' in model_df_test.columns:\n",
    "         display_cols.append('numeric_score_margin_invation')\n",
    "    print(model_df_test[display_cols].head())\n",
    "\n",
    "else:\n",
    "    print(\"Skipping prediction and evaluation as model or test data is not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff032a6f",
   "metadata": {},
   "source": [
    "## 10: CSV出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "192c98aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Exporting Test Predictions to CSV ---\n",
      "Successfully exported test predictions to: win_probability_predictions_ipynb.csv\n",
      "\n",
      "--- Win probability prediction notebook execution finished (potentially) ---\n"
     ]
    }
   ],
   "source": [
    "if 'model_df_test' in locals() and isinstance(model_df_test, pd.DataFrame) and not model_df_test.empty:\n",
    "    output_csv_path = 'win_probability_predictions_ipynb.csv' # Notebookからの出力とわかるように名前変更\n",
    "    print(f\"\\n--- Exporting Test Predictions to CSV ---\")\n",
    "    try:\n",
    "        model_df_test.to_csv(output_csv_path, index=False, encoding='utf-8')\n",
    "        print(f\"Successfully exported test predictions to: {output_csv_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error exporting to CSV: {e}\")\n",
    "else:\n",
    "    print(\"\\nSkipping CSV export because 'model_df_test' was not generated, is empty, or is not a DataFrame.\")\n",
    "\n",
    "print(\"\\n--- Win probability prediction notebook execution finished (potentially) ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pbl)",
   "language": "python",
   "name": "pbl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
