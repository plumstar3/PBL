{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5578556",
   "metadata": {},
   "source": [
    "## 1: ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddc366b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupShuffleSplit, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, log_loss, brier_score_loss, classification_report\n",
    "import numpy as np\n",
    "from typing import Optional\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaae261f",
   "metadata": {},
   "source": [
    "## 2: データ読み込み・前処理関数の定義 (load_and_process_pbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9953bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_pbp(db_path: str, limit_rows: Optional[int] = None) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    SQLiteデータベースからプレイバイプレイデータを読み込み、データ型を処理し、\n",
    "    ホームチームの勝敗情報を計算して元のデータに結合します。\n",
    "    (省略... 関数の内容は元のスクリプトと同じ)\n",
    "    \"\"\"\n",
    "    print(f\"--- Starting data loading and processing ---\")\n",
    "    print(f\"Database path: {db_path}\")\n",
    "    if limit_rows:\n",
    "        print(f\"Row limit: {limit_rows}\")\n",
    "    else:\n",
    "        print(\"Row limit: None (loading all rows)\")\n",
    "\n",
    "    try:\n",
    "        # 1. SQLiteデータベースへの接続\n",
    "        print(\"Connecting to database...\")\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        print(\"Database connection successful.\")\n",
    "\n",
    "        # 2. SQLクエリの構築\n",
    "        query = \"\"\"\n",
    "        SELECT\n",
    "            game_id, eventnum, eventmsgtype, period, pctimestring,\n",
    "            homedescription, neutraldescription, visitordescription,\n",
    "            score, scoremargin\n",
    "        FROM\n",
    "            play_by_play\n",
    "        \"\"\"\n",
    "        if limit_rows:\n",
    "            query += f\" LIMIT {limit_rows};\"\n",
    "        else:\n",
    "            query += \";\"\n",
    "\n",
    "        print(\"Executing SQL query...\")\n",
    "        # 3. クエリ実行とDataFrameへの読み込み\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "        print(f\"Successfully loaded {len(df)} rows into DataFrame.\")\n",
    "\n",
    "        # 4. データベース接続を閉じる\n",
    "        conn.close()\n",
    "        print(\"Database connection closed.\")\n",
    "\n",
    "        # 5. データ型の確認と変換\n",
    "        print(\"Processing data types...\")\n",
    "        df['game_id'] = df['game_id'].astype(str)\n",
    "        df['pctimestring'] = df['pctimestring'].astype(str)\n",
    "        df['score'] = df['score'].astype(str)\n",
    "        df['scoremargin'] = df['scoremargin'].astype(str)\n",
    "        df['eventnum'] = pd.to_numeric(df['eventnum'], errors='coerce')\n",
    "        df['eventmsgtype'] = pd.to_numeric(df['eventmsgtype'], errors='coerce')\n",
    "        df['period'] = pd.to_numeric(df['period'], errors='coerce')\n",
    "        desc_cols = ['homedescription', 'neutraldescription', 'visitordescription']\n",
    "        for col in desc_cols:\n",
    "            df[col] = df[col].fillna('')\n",
    "        print(\"Data type processing complete.\")\n",
    "\n",
    "        # --- 最終スコアの取得と勝敗判定 ---\n",
    "        print(\"\\nAttempting to determine game outcomes...\")\n",
    "        game_outcomes = pd.Series(dtype=int) # 空のSeriesを初期化\n",
    "\n",
    "        end_game_events = df[(df['eventmsgtype'] == 13) & (df['score'].str.contains(' - ', na=False))].copy()\n",
    "\n",
    "        if not end_game_events.empty:\n",
    "            end_game_events = end_game_events.dropna(subset=['period'])\n",
    "            if not end_game_events.empty:\n",
    "                end_game_events['period'] = end_game_events['period'].astype(int)\n",
    "                final_events = end_game_events.sort_values('period').groupby('game_id').last()\n",
    "\n",
    "                if 'score' in final_events.columns:\n",
    "                    scores_split = final_events['score'].str.split(' - ', expand=True)\n",
    "                    scores_split.columns = ['home_score', 'visitor_score']\n",
    "                    scores_split['home_score'] = pd.to_numeric(scores_split['home_score'], errors='coerce')\n",
    "                    scores_split['visitor_score'] = pd.to_numeric(scores_split['visitor_score'], errors='coerce')\n",
    "                    scores_split = scores_split.dropna(subset=['home_score', 'visitor_score'])\n",
    "\n",
    "                    if not scores_split.empty:\n",
    "                        scores_split['home_win'] = (scores_split['home_score'] > scores_split['visitor_score']).astype(int)\n",
    "                        game_outcomes = scores_split['home_win']\n",
    "                        print(f\"Determined outcomes for {len(game_outcomes)} games.\")\n",
    "                        if limit_rows:\n",
    "                            print(\"[Warning] Game outcomes may be incomplete due to the row limit.\")\n",
    "                    # else: (No need for print here in a function, caller can check)\n",
    "                # else:\n",
    "            # else:\n",
    "        # else:\n",
    "\n",
    "        print(\"Merging game outcomes back to the main DataFrame...\")\n",
    "        if not game_outcomes.empty:\n",
    "             df_with_outcome = df.merge(game_outcomes.rename('home_win'), on='game_id', how='left')\n",
    "        else:\n",
    "             print(\"No game outcomes determined, adding 'home_win' column with NaN.\")\n",
    "             df['home_win'] = pd.NA\n",
    "             df_with_outcome = df\n",
    "\n",
    "        print(\"--- Data loading and processing finished ---\")\n",
    "        return df_with_outcome\n",
    "\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"\\n--- Database Error ---\")\n",
    "        print(f\"An error occurred while interacting with the database: {e}\")\n",
    "        return None\n",
    "    except FileNotFoundError:\n",
    "        print(f\"\\n--- File Not Found Error ---\")\n",
    "        print(f\"Error: The database file was not found at the specified path: {db_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"\\n--- An Unexpected Error Occurred ---\")\n",
    "        print(f\"Error details: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758cad44",
   "metadata": {},
   "source": [
    "## 3: 特徴量エンジニアリング用関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b81bae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_time_to_seconds(time_str):\n",
    "    \"\"\" 'MM:SS' 形式の文字列を秒に変換 \"\"\"\n",
    "    if isinstance(time_str, str) and ':' in time_str:\n",
    "        try:\n",
    "            minutes, seconds = map(int, time_str.split(':'))\n",
    "            return minutes * 60 + seconds\n",
    "        except ValueError:\n",
    "            return None # パースエラー\n",
    "    return None\n",
    "\n",
    "def calculate_seconds_elapsed(row):\n",
    "    \"\"\" 試合開始からの経過秒数を計算 \"\"\"\n",
    "    period = row['period']\n",
    "    pctimestring = row['pctimestring']\n",
    "\n",
    "    if pd.isna(period) or period < 1:\n",
    "        return None\n",
    "\n",
    "    seconds_in_period = parse_time_to_seconds(pctimestring)\n",
    "    if seconds_in_period is None:\n",
    "        return None\n",
    "\n",
    "    seconds_per_period = 720 if period <= 4 else 300\n",
    "    seconds_elapsed_in_current_period = seconds_per_period - seconds_in_period\n",
    "\n",
    "    if seconds_elapsed_in_current_period < 0 or seconds_elapsed_in_current_period > seconds_per_period:\n",
    "         return None\n",
    "\n",
    "    if period <= 4:\n",
    "        total_seconds_elapsed = (period - 1) * 720 + seconds_elapsed_in_current_period\n",
    "    else:\n",
    "        total_seconds_elapsed = 4 * 720 + (period - 5) * 300 + seconds_elapsed_in_current_period\n",
    "    return total_seconds_elapsed\n",
    "\n",
    "def process_score_margin(margin_str):\n",
    "    \"\"\" scoremargin を数値に変換 ('TIE' -> 0) \"\"\"\n",
    "    if margin_str == 'TIE':\n",
    "        return 0\n",
    "    elif pd.isna(margin_str) or margin_str == '':\n",
    "         return None\n",
    "    else:\n",
    "        try:\n",
    "            return int(str(margin_str).replace('+', ''))\n",
    "        except ValueError:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62ada2e",
   "metadata": {},
   "source": [
    "## 4 設定とデータ読み込みの実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d926ad6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting data loading and processing ---\n",
      "Database path: C:\\Users\\amilu\\Projects\\vsCodeFile\\PBL\\nba.sqlite\n",
      "Row limit: 45616\n",
      "Connecting to database...\n",
      "Database connection successful.\n",
      "Executing SQL query...\n",
      "Successfully loaded 45616 rows into DataFrame.\n",
      "Database connection closed.\n",
      "Processing data types...\n",
      "Data type processing complete.\n",
      "\n",
      "Attempting to determine game outcomes...\n",
      "Determined outcomes for 99 games.\n",
      "[Warning] Game outcomes may be incomplete due to the row limit.\n",
      "Merging game outcomes back to the main DataFrame...\n",
      "--- Data loading and processing finished ---\n",
      "\n",
      "Shape of loaded data: (45616, 11)\n"
     ]
    }
   ],
   "source": [
    "#研究室PC用path\n",
    "db_file = r'C:\\Users\\amilu\\Projects\\vsCodeFile\\PBL\\nba.sqlite'\n",
    "#ノートPC用path\n",
    "#db_file = 'C:\\Workspace\\PBL\\\\nba.sqlite'\n",
    "\n",
    "limit_rows = 45616\n",
    "# limit_rows = None # 全データの場合\n",
    "\n",
    "df_processed = load_and_process_pbp(db_file, limit_rows=limit_rows)\n",
    "\n",
    "# 読み込み結果の確認\n",
    "if df_processed is not None:\n",
    "    print(\"\\nShape of loaded data:\", df_processed.shape)\n",
    "    df_processed.head() # 先頭数行を表示\n",
    "else:\n",
    "    print(\"Data loading failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dc97f4",
   "metadata": {},
   "source": [
    "## 5: 特徴量エンジニアリングの実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bce3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Feature Engineering ---\n",
      "Calculating total seconds elapsed...\n",
      "Processing score margin...\n"
     ]
    }
   ],
   "source": [
    "if df_processed is not None:\n",
    "    print(\"\\n--- Feature Engineering ---\")\n",
    "\n",
    "    print(\"Calculating total seconds elapsed...\")\n",
    "    df_processed['seconds_elapsed'] = df_processed.apply(calculate_seconds_elapsed, axis=1)\n",
    "\n",
    "    print(\"Processing score margin...\")\n",
    "    # Step 1: 'TIE' や数値変換可能なものを数値に変換 (NoneはNoneのまま)\n",
    "    df_processed['numeric_score_margin'] = df_processed['scoremargin'].apply(process_score_margin)\n",
    "\n",
    "    # Step 2: game_id ごとに並べ替え、欠損値 (None) を直前の有効な値で前方補完 (ffill)\n",
    "    print(\"Forward filling missing 'numeric_score_margin' within each game...\")\n",
    "    # game_id と eventnum でソートすることが重要\n",
    "    df_processed = df_processed.sort_values(by=['game_id', 'eventnum'])\n",
    "    df_processed['numeric_score_margin'] = df_processed.groupby('game_id')['numeric_score_margin'].ffill()\n",
    "\n",
    "    # ffill 後も NaN が残る場合がある（ゲームの最初の数プレイなど、前に有効な値がない場合）\n",
    "    # これらは後続の dropna で処理されるか、別途 0 などで埋める判断も可能\n",
    "    # print(\"NaN count in numeric_score_margin after ffill:\", df_processed['numeric_score_margin'].isnull().sum())\n",
    "\n",
    "\n",
    "    # 結果の確認\n",
    "    print(\"\\nPreview of processed time and score margin features:\")\n",
    "    print(df_processed[['game_id', 'eventnum', 'period', 'pctimestring', 'seconds_elapsed', 'scoremargin', 'numeric_score_margin']].head(15)) # 少し多めに表示してffillの効果を確認"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7572d0cb",
   "metadata": {},
   "source": [
    "## 6: モデル用データ準備 (フィルタリング)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bbda1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data Preparation for Modeling ---\n",
      "Filtering data for modeling...\n",
      "Rows before filtering: 45616\n",
      "Rows after filtering invalid/unnecessary entries: 10940\n"
     ]
    }
   ],
   "source": [
    "if df_processed is not None:\n",
    "    print(\"\\n--- Data Preparation for Modeling ---\")\n",
    "    print(\"Filtering data for modeling...\")\n",
    "    initial_rows = len(df_processed)\n",
    "    \n",
    "    # 欠損値の確認 (フィルタリング前)\n",
    "    # print(\"NaN counts before filtering:\")\n",
    "    # print(df_processed[['home_win', 'seconds_elapsed', 'numeric_score_margin', 'period']].isnull().sum())\n",
    "\n",
    "    model_df = df_processed.dropna(subset=['home_win', 'seconds_elapsed', 'numeric_score_margin', 'period'])\n",
    "    model_df = model_df[model_df['period'] > 0]\n",
    "    model_df = model_df[model_df['eventmsgtype'] != 12] # \"Start Period\" イベントを除外\n",
    "\n",
    "    filtered_rows = len(model_df)\n",
    "    print(f\"Rows before filtering: {initial_rows}\")\n",
    "    print(f\"Rows after filtering invalid/unnecessary entries: {filtered_rows}\")\n",
    "    \n",
    "    if filtered_rows > 0:\n",
    "        model_df.head()\n",
    "    else:\n",
    "        print(\"No data left after filtering.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d858e58",
   "metadata": {},
   "source": [
    "## 7: 特徴量とターゲットの選択、訓練/テスト分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cacb381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into training and testing sets (game-aware)...\n",
      "Training set size: 8676\n",
      "Testing set size: 2264\n"
     ]
    }
   ],
   "source": [
    "if 'model_df' in locals() and not model_df.empty:\n",
    "    features = ['numeric_score_margin', 'seconds_elapsed']\n",
    "    target = 'home_win'\n",
    "    X = model_df[features]\n",
    "    y = model_df[target].astype(int)\n",
    "\n",
    "    print(\"Splitting data into training and testing sets (game-aware)...\")\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    \n",
    "    if model_df['game_id'].nunique() < 2:\n",
    "        print(\"Warning: Not enough unique games for GroupShuffleSplit. Using simple train_test_split or manual handling might be needed.\")\n",
    "        # 代替処理: もしゲームが1つしかない場合など、ここではエラーにはせず、\n",
    "        # 訓練データのみとするか、エラーを発生させるかなどの判断が必要\n",
    "        if len(X) > 1: # 最低2サンプルあれば通常の分割を試みる（ただしグループ考慮なし）\n",
    "             train_idx, test_idx = train_test_split(range(len(X)), test_size=0.2, random_state=42, stratify=y if y.nunique() > 1 else None)\n",
    "        else: # サンプルが少なすぎる場合\n",
    "            train_idx, test_idx = range(len(X)), []\n",
    "            print(\"Too few samples for splitting. Using all as training data.\")\n",
    "    else:\n",
    "        train_idx, test_idx = next(gss.split(X, y, groups=model_df['game_id']))\n",
    "\n",
    "    if len(train_idx) > 0 and len(test_idx) > 0:\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        print(f\"Training set size: {len(X_train)}\")\n",
    "        print(f\"Testing set size: {len(X_test)}\")\n",
    "    elif len(train_idx) > 0: # テストセットが作れなかった場合\n",
    "        print(f\"Only training data available. Training set size: {len(X_train)}\")\n",
    "        X_test, y_test = pd.DataFrame(columns=X.columns), pd.Series(dtype=y.dtype) # 空のテストセット\n",
    "    else:\n",
    "        print(\"Could not create valid train/test splits. Check data and group sizes.\")\n",
    "else:\n",
    "    print(\"Skipping train/test split as model_df is not available or empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af041df",
   "metadata": {},
   "source": [
    "## 8: モデル訓練 (スケーリングとロジスティック回帰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0c91c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Training ---\n",
      "Scaling features...\n",
      "Training Logistic Regression model...\n",
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "if 'X_train' in locals() and not X_train.empty:\n",
    "    print(\"\\n--- Model Training ---\")\n",
    "    print(\"Scaling features...\")\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    \n",
    "    # テストデータがある場合のみスケーリング\n",
    "    if not X_test.empty:\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "    else:\n",
    "        X_test_scaled = np.array([]) # 空の配列\n",
    "\n",
    "    print(\"Training Logistic Regression model...\")\n",
    "    model = LogisticRegression(random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    print(\"Model training complete.\")\n",
    "else:\n",
    "    print(\"Skipping model training as training data is not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a0b565",
   "metadata": {},
   "source": [
    "##  9: 予測と評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e317e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Prediction and Evaluation ---\n",
      "Model Evaluation Results:\n",
      "  Accuracy: 0.6798\n",
      "  ROC AUC:  0.7376\n",
      "  Log Loss: 0.5808\n",
      "  Brier Score: 0.2036\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.70      0.72      1334\n",
      "           1       0.60      0.65      0.63       930\n",
      "\n",
      "    accuracy                           0.68      2264\n",
      "   macro avg       0.67      0.68      0.67      2264\n",
      "weighted avg       0.68      0.68      0.68      2264\n",
      "\n",
      "\n",
      "Reversing the sign of 'numeric_score_margin' in model_df_test...\n",
      "Sign reversal of 'numeric_score_margin_invation' complete.\n",
      "   scoremargin  numeric_score_margin  numeric_score_margin_invation\n",
      "12           2                   2.0                           -2.0\n",
      "15           4                   4.0                           -4.0\n",
      "22           3                   3.0                           -3.0\n",
      "24           2                   2.0                           -2.0\n",
      "28         TIE                   0.0                           -0.0\n",
      "\n",
      "First 5 rows of test data with predicted win probability:\n",
      "       game_id  eventnum  period pctimestring  score scoremargin  \\\n",
      "12  0029600012        13       1        10:40  0 - 2           2   \n",
      "15  0029600012        16       1        10:05  0 - 4           4   \n",
      "22  0029600012        24       1         9:24  1 - 4           3   \n",
      "24  0029600012        26       1         9:24  2 - 4           2   \n",
      "28  0029600012        29       1         8:53  4 - 4         TIE   \n",
      "\n",
      "    numeric_score_margin  seconds_elapsed  home_win  win_probability_pred  \\\n",
      "12                   2.0               80         0              0.436648   \n",
      "15                   4.0              115         0              0.371446   \n",
      "22                   3.0              156         0              0.405211   \n",
      "24                   2.0              156         0              0.438758   \n",
      "28                   0.0              187         0              0.508119   \n",
      "\n",
      "    numeric_score_margin_invation  \n",
      "12                           -2.0  \n",
      "15                           -4.0  \n",
      "22                           -3.0  \n",
      "24                           -2.0  \n",
      "28                           -0.0  \n"
     ]
    }
   ],
   "source": [
    "if 'model' in locals() and 'X_test_scaled' in locals() and X_test_scaled.shape[0] > 0: # テストデータがあるか確認\n",
    "    print(\"\\n--- Prediction and Evaluation ---\")\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    y_pred_class = model.predict(X_test_scaled)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred_class)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    logloss = log_loss(y_test, y_pred_proba)\n",
    "    brier = brier_score_loss(y_test, y_pred_proba)\n",
    "\n",
    "    print(f\"Model Evaluation Results:\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  ROC AUC:  {auc:.4f}\")\n",
    "    print(f\"  Log Loss: {logloss:.4f}\")\n",
    "    print(f\"  Brier Score: {brier:.4f}\")\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred_class))\n",
    "\n",
    "    # テストデータに予測結果を結合\n",
    "    model_df_test = model_df.iloc[test_idx].copy()\n",
    "    model_df_test['win_probability_pred'] = y_pred_proba\n",
    "\n",
    "    # numeric_score_margin の正負反転\n",
    "    if 'numeric_score_margin' in model_df_test.columns:\n",
    "        print(\"\\nReversing the sign of 'numeric_score_margin' in model_df_test...\")\n",
    "        model_df_test['numeric_score_margin_invation'] = model_df_test['numeric_score_margin'] * -1\n",
    "        print(\"Sign reversal of 'numeric_score_margin_invation' complete.\")\n",
    "        print(model_df_test[['scoremargin', 'numeric_score_margin', 'numeric_score_margin_invation']].head())\n",
    "    else:\n",
    "        print(\"\\nWarning: 'numeric_score_margin' column not found in model_df_test.\")\n",
    "\n",
    "\n",
    "    print(\"\\nFirst 5 rows of test data with predicted win probability:\")\n",
    "    # 表示するカラムを調整\n",
    "    display_cols = ['game_id', 'eventnum', 'period', 'pctimestring', 'score', 'scoremargin', 'numeric_score_margin', 'seconds_elapsed', 'home_win', 'win_probability_pred']\n",
    "    if 'numeric_score_margin_invation' in model_df_test.columns:\n",
    "         display_cols.append('numeric_score_margin_invation')\n",
    "    print(model_df_test[display_cols].head())\n",
    "\n",
    "else:\n",
    "    print(\"Skipping prediction and evaluation as model or test data is not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff032a6f",
   "metadata": {},
   "source": [
    "## 10: CSV出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192c98aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Exporting Test Predictions to CSV ---\n",
      "Successfully exported test predictions to: win_probability_predictions.ipynb.csv\n",
      "\n",
      "--- Win probability prediction notebook execution finished (potentially) ---\n"
     ]
    }
   ],
   "source": [
    "if 'model_df_test' in locals() and isinstance(model_df_test, pd.DataFrame) and not model_df_test.empty:\n",
    "    output_csv_path = 'win_probability_predictions_ipynb.csv' # Notebookからの出力とわかるように名前変更\n",
    "    print(f\"\\n--- Exporting Test Predictions to CSV ---\")\n",
    "    try:\n",
    "        model_df_test.to_csv(output_csv_path, index=False, encoding='utf-8')\n",
    "        print(f\"Successfully exported test predictions to: {output_csv_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error exporting to CSV: {e}\")\n",
    "else:\n",
    "    print(\"\\nSkipping CSV export because 'model_df_test' was not generated, is empty, or is not a DataFrame.\")\n",
    "\n",
    "print(\"\\n--- Win probability prediction notebook execution finished (potentially) ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pbl)",
   "language": "python",
   "name": "pbl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
